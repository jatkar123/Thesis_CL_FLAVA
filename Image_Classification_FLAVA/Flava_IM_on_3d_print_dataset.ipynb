{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/IAIS/jraghu/.local/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "from transformers import AutoImageProcessor, FlavaImageModel, FlavaModel, FlavaFeatureExtractor, AutoModelForCausalLM\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/home/IAIS/jraghu/.cache/huggingface/datasets/cmudrc___parquet/cmudrc--3d-printed-or-not-c7389bae8477e941/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "100%|██████████| 1/1 [00:00<00:00, 160.94it/s]\n"
     ]
    }
   ],
   "source": [
    "#This is a set of 60k 3d printed images or look-alike images with each segment almost having a 50% images. It is a medium sized image classification dataset which FLAVA has never before seen r been trained on previously\n",
    "dataset = load_dataset(\"cmudrc/3d-printed-or-not\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the dictionary to arrays\n",
    "features_array = dataset['train']['image'][:-100]\n",
    "labels_array = dataset['train']['label'][:-100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into train and test sets\n",
    "# train_features, test_features, train_labels, test_labels = train_test_split(\n",
    "#     features_array, labels_array, test_size=0.2, random_state=42\n",
    "# )\n",
    "#keeping a set of 100 images untouched for testing purpose\n",
    "test_set_features = dataset['train']['image'][-100:]\n",
    "test_set_labels = dataset['train']['label'][-100:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n"
     ]
    }
   ],
   "source": [
    "#Flava model calls for Image classification on Image encoder\n",
    "image_processor = AutoImageProcessor.from_pretrained(\"facebook/flava-full\")\n",
    "model = FlavaImageModel.from_pretrained(\"facebook/flava-full\").cuda().eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51420"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rgb_images_train = []\n",
    "\n",
    "\n",
    "#Iterate throught he MNIST dataset to convert it into 3 channel and append them into a list\n",
    "for sample, label in zip(features_array, labels_array):\n",
    "  \n",
    "  rgb_image = sample.convert('RGB')\n",
    "  \n",
    "  # Append the RGB image to the list\n",
    "  rgb_images_train.append(rgb_image)\n",
    "\n",
    "len(rgb_images_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BAtching the dataset to get image features in batches to enable the efficeint and complete use of the GPU\n",
    "\n",
    "def batching(batch_size, rgb_images):\n",
    "    \"\"\"\n",
    "    Batch_size-> is the number o batches you want to process the dataset in; rgb_images-> the dataset list in RGB form\n",
    "    returns a list of features of lists in tensors\n",
    "    \"\"\"\n",
    "\n",
    "    # Define the batch size\n",
    "    batch_size = 10\n",
    "\n",
    "    features_in_Tensor = []\n",
    "    # Calculate the number of batches\n",
    "    num_batches = len(rgb_images) // batch_size\n",
    "\n",
    "    # Process the images in batches\n",
    "    for batch_idx in range(num_batches):\n",
    "        # Get the start and end indices for the current batch\n",
    "        start_idx = batch_idx * batch_size\n",
    "        end_idx = start_idx + batch_size\n",
    "\n",
    "        # Get the images for the current batch\n",
    "        batch_images = rgb_images[start_idx:end_idx]\n",
    "\n",
    "        # Process the images in the current batch\n",
    "        processed_images = []\n",
    "        with torch.no_grad():\n",
    "            for image in batch_images:\n",
    "                # Your processing logic here\n",
    "\n",
    "                #processed_images = fe(image, return_tensors=\"pt\").to(\"cuda\")\n",
    "                #image_features = flava.get_image_features(**processed_images)[:, 0, :]\n",
    "                processed_images = image_processor(image, return_tensors=\"pt\").to(\"cuda\")\n",
    "                image_features = model(**processed_images)\n",
    "                image_features = image_features.last_hidden_state[:, 0, :]\n",
    "                \n",
    "                features_in_Tensor.append(image_features.detach().cpu().numpy())\n",
    "        # Do something with the processed images\n",
    "        \n",
    "        \n",
    "        # Clear memory of the processed images if no longer needed\n",
    "        torch.cuda.empty_cache()\n",
    "        del processed_images, image_features\n",
    "\n",
    "    return features_in_Tensor\n",
    "\n",
    "features_3d_print_train = batching(batch_size=10, rgb_images=rgb_images_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load and preprocess the images to convert each Jpeg image into np array type\n",
    "# def preprocess_images(image_array):\n",
    "#     num_images = len(image_array)\n",
    "\n",
    "#     # Create an empty array to store the flattened and normalized images\n",
    "#     processed_images = np.zeros((num_images, height * width * channels))\n",
    "\n",
    "#     for img in range(num_images):\n",
    "        \n",
    "\n",
    "#         # Normalize the pixel values to a range between 0 and 1 (if the original range is [0, 255])\n",
    "#         image = np.array(img) / 255.0\n",
    "\n",
    "#         # Flatten the 3D image into a 1D feature vector\n",
    "#         processed_images[img] = image.flatten()\n",
    "\n",
    "#     return processed_images\n",
    "\n",
    "# # Define the dimensions of the images\n",
    "# height = 256\n",
    "# width = 256\n",
    "# channels = 3  # Assuming RGB images, change to 1 for grayscale\n",
    "\n",
    "# # calling the preprocessing fn\n",
    "# processed_images_train = preprocess_images(train_features)\n",
    "# processed_images_test = preprocess_images(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set Accuracy: 0.9447685725398678\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Converting the tensor into Numpy \n",
    "#features = features_in_Numpy.detach().numpy()\n",
    "features_in_Numpy = np.squeeze(features_3d_print_train, axis=1)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_in_Numpy, labels_array, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a logistic regression model with L-BFGS optimization\n",
    "logistic_model = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "\n",
    "# Train the logistic regression model\n",
    "logistic_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = logistic_model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Training set Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tetsing set Accuracy: 0.8\n"
     ]
    }
   ],
   "source": [
    "\n",
    "rgb_images_test = []\n",
    "\n",
    "\n",
    "#Iterate throught he MNIST dataset to convert it into 3 channel and append them into a list\n",
    "for sample, label in zip(test_set_features, test_set_labels):\n",
    "  \n",
    "  \n",
    "  rgb_image = sample.convert('RGB')\n",
    "  \n",
    "  # Append the RGB image to the list\n",
    "  rgb_images_test.append(rgb_image)\n",
    "\n",
    "\n",
    "features_test = batching(batch_size=10, rgb_images=rgb_images_test)\n",
    "features_test = np.squeeze(features_test, axis=1)\n",
    "\n",
    "# Make predictions on the unseen dataset using the same Logistic regression linear classifier\n",
    "y_pred_unseen = logistic_model.predict(features_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(test_set_labels, y_pred_unseen)\n",
    "print(\"tetsing set Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
