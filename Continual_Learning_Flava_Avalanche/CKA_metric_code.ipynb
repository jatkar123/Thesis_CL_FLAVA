{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/IAIS/jraghu/.local/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#importing necessary libraries\n",
    "from transformers import AutoProcessor, FlavaModel, FlavaImageModel, AutoImageProcessor, FlavaFeatureExtractor\n",
    "import numpy as np\n",
    "from torchmultimodal.models.flava.model import flava_model_for_classification\n",
    "from transformers import FlavaProcessor, FlavaForPreTraining\n",
    "import torchvision\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import wandb\n",
    "\n",
    "from tqdm import tqdm\n",
    "from avalanche.benchmarks.generators import nc_benchmark, ni_benchmark\n",
    "from avalanche.benchmarks.datasets import MNIST, CUB200\n",
    "\n",
    "from torchvision.transforms import Compose, ToTensor, Normalize, RandomCrop\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "CKA Score: 0.46880094210306805\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import pairwise_kernels\n",
    "from torchvision.datasets import CIFAR100\n",
    "from torch.utils.data import DataLoader\n",
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define a function to compute the CKA\n",
    "def cka(kernel1, kernel2):\n",
    "    \n",
    "    # Compute CKA\n",
    "    cka_num = np.linalg.norm((kernel1 * kernel2))\n",
    "    cka_den1 = np.linalg.norm((kernel1 * kernel1))\n",
    "    cka_den2 = np.linalg.norm((kernel2 * kernel2))\n",
    "    cka_value = cka_num/(cka_den1*cka_den2)\n",
    "\n",
    "\n",
    "\n",
    "    return cka_value\n",
    "\n",
    "# Check if a GPU is available, and set the device accordingly\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load pre-trained models\n",
    "image_processor = AutoImageProcessor.from_pretrained(\"facebook/flava-full\")\n",
    "model1 = FlavaImageModel.from_pretrained(\"facebook/flava-full\").eval().to(device) #Frozen model\n",
    "model2 = FlavaImageModel.from_pretrained(\"facebook/flava-full\").eval().to(device) #partly-frozen model\n",
    "\n",
    "\n",
    "\n",
    "# Freeze some layers (e.g., the first 3 layers)\n",
    "for param in model1.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "\n",
    "child_counter = 0\n",
    "for child in model2.children():   \n",
    "    if child_counter < 2: #2 for 2 child frozen which gives best results as of now\n",
    "        for param in child.parameters():\n",
    "            param.requires_grad = False\n",
    "        child_counter += 1\n",
    "\n",
    "\n",
    "\n",
    "# Define a function to extract activations from a specific layer\n",
    "def get_activations(model, x, layer_name):\n",
    "    layers = list(model.children())\n",
    "    activations = []\n",
    "    for i, layer in enumerate(layers):\n",
    "        outpts = model(**x)\n",
    "        features = outpts.last_hidden_state  #.view(outpts.last_hidden_state.size(0), -1) \n",
    "        if i == layer_name:\n",
    "            return features\n",
    "        activations.append(features)\n",
    "    return features\n",
    "\n",
    "# Prepare data \n",
    "resize_transform = transforms.Resize((224, 224))\n",
    "grayscale_transform = transforms.Grayscale(num_output_channels=3)\n",
    "data_transform = Compose([\n",
    "    resize_transform,\n",
    "    grayscale_transform,\n",
    "    ToTensor()\n",
    "    \n",
    "])\n",
    "\n",
    "\n",
    "cifar100_dataset = CIFAR100(root='./data/cifar100', train=True, transform=data_transform, download=True)\n",
    "dataloader = DataLoader(cifar100_dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "# Extract representations from a specific layer\n",
    "layer_name = 2  # Example layer number\n",
    "\n",
    "for data in dataloader:\n",
    "    inputs, _ = data\n",
    "    \n",
    "    inputs = image_processor(images=inputs, return_tensors=\"pt\").to(\"cuda\")\n",
    "    outputs1 = model1(**inputs)\n",
    "    outputs2 = model2(**inputs)\n",
    "\n",
    "    \n",
    "    representations1 = get_activations(model1, inputs, layer_name).detach().cpu().numpy()\n",
    "    representations2 = get_activations(model2, inputs, layer_name).detach().cpu().numpy()\n",
    "    break  # Process one batch (you can modify this loop to process more data)\n",
    "\n",
    "\n",
    "representations1 = np.squeeze(representations1, axis=0)\n",
    "representations2 = np.squeeze(representations2, axis=0)\n",
    "\n",
    "\n",
    "# Calculate the CKA score\n",
    "cka_score = cka(representations1, representations2)\n",
    "print(\"CKA Score:\", cka_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
